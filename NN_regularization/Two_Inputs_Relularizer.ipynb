{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Neural Network as a Regularizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we will try to use a nn with two inputs: the image (blurry or not) and the projection (exact one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as dsets\n",
    "from skimage import transform\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from vis_utils import *\n",
    "import random\n",
    "import h5py\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we will create the dataset to train our nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our brain dataset, and we add random values to each pixel in order to blurry images. All the values add are summed to create our regulized norm we want to minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resulting_brains = []\n",
    "vars_ = []\n",
    "number_brains_blurried = 10\n",
    "\n",
    "for l in range(len(brains)):\n",
    "    test_brain = brains[l]/1000\n",
    "    resulting_brains.append(test_brain)\n",
    "    vars_.append(0)\n",
    "    for i in range(number_brains_blurried):\n",
    "        var = 0\n",
    "        changed_brain = np.copy(test_brain)\n",
    "        for j in range(64):\n",
    "            for k in range(64):\n",
    "                value = changed_brain[k][j]\n",
    "                add = np.random.randint(max(-value, -1000+100*i), 1000-100*i)/1000\n",
    "                #print(changed_brain[k][j])\n",
    "                changed_brain[k][j] = value + add\n",
    "                #print(changed_brain[k][j])\n",
    "\n",
    "                var = var + add*add/1000\n",
    "        resulting_brains.append(changed_brain)\n",
    "        vars_.append(var)\n",
    "        \n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    print(p)\n",
    "    return a[p], b[p]\n",
    "\n",
    "resulting_brains, vars_ = shuffle(resulting_brains, vars_, random_state=0)\n",
    "\n",
    "print(vars_[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
